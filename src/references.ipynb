{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ed17b0",
   "metadata": {},
   "source": [
    "# Generate CAID-2 references\n",
    "\n",
    "DisProt data can be obtained directly exporting the relevant database collections (ask the developers): \n",
    "\n",
    "```bash\n",
    "# 18 Aug 2022\n",
    "mongoexport -d disprot8 -c entries_2022_06 -o disprot_entries_2022_06.mjson\n",
    "mongoexport -d disprot8 -c entries_2022_12_c -o disprot_entries_2022_12_c.mjson\n",
    "scp moros:disprot_entries* .\n",
    "```\n",
    "Or using the download service from the website (lastest annotations might not be available to the public). Note the formats are slightly different.\n",
    "\n",
    "AlphaFold (processed) predictions can be obtained using the code in the [AlphaFold-disorder](https://github.com/BioComputingUP/AlphaFold-disorder) repository.\n",
    "\n",
    "Preliminary steps:\n",
    "```bash\n",
    "# Generate the folder structure\n",
    "mkdir -p ../data/{disprot,sifts,alphafold,output/references}\n",
    "    \n",
    "# Download data (18 Aug 2022)\n",
    "wget -O ../data/sifts/ ftp://ftp.ebi.ac.uk/pub/databases/msd/sifts/flatfiles/tsv/uniprot_segments_observed.tsv.gz\n",
    "wget -O ../data/disprot/ http://purl.obolibrary.org/obo/go/go-basic.obo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6883c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx\n",
    "import numpy as np\n",
    "import obonet  # conda install -c biobuilds obonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128d9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_obo_file = \"../data/disprot/go-basic.obo\"\n",
    "disprot_old_file = \"../data/disprot/disprot_entries_2022_06.mjson\"\n",
    "disprot_new_file = \"../data/disprot/disprot_entries_2022_12_c.mjson\"\n",
    "sifts_file = \"../data/sifts/uniprot_segments_observed.tsv.gz\"\n",
    "\n",
    "# Optional\n",
    "alphafold_dir = \"../data/alphafold\"\n",
    "gene3d_file = \"\"\n",
    "\n",
    "# Output\n",
    "references_dir = \"../data/output/references\"\n",
    "raw_dataset_file = \"../data/output/raw_dataset.tsv\"\n",
    "dataset_file = \"../data/output/dataset.tsv\"\n",
    "fasta_new_file = \"../data/output/disprot_new.fasta\"\n",
    "fasta_old_file = \"../data/output/disprot_old.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_region(df_:pd.DataFrame, start_col:str='start', end_col:str='end', res_col:str='reg_position') -> pd.DataFrame:\n",
    "    df_[res_col] = list(range(int(df_[start_col]), int(df_[end_col]) + 1, 1))\n",
    "    return df_\n",
    "\n",
    "def expand_sequence(df_:pd.DataFrame, seq_column:str='sequence', res_col:str='seq_aa') -> pd.DataFrame:\n",
    "    df_[res_col] = [(i+1, aa) for i, aa in enumerate(df_[seq_column])]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a9e33",
   "metadata": {},
   "source": [
    "## Associate DisProt annotation terms to CAID challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9755b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDPO terms\n",
    "data_idpo = [('IDPO:00076', 'disorder'), ('IDPO:00077', 'disorder'), ('IDPO:00078', 'disorder'), \n",
    "                   ('IDPO:00501', 'linker'), ('IDPO:00502', 'linker'), ('IDPO:00503', 'linker'), \n",
    "                   ('IDPO:00504', 'linker'), ('IDPO:00049', 'transition'), ('IDPO:00050', 'transition'), \n",
    "                   ('IDPO:00051', 'transition'), ('IDPO:00052', 'transition'), ('IDPO:00053', 'transition'), \n",
    "                   ('IDPO:00060', 'transition'), ('IDPO:00055', 'transition'), ('IDPO:00056', 'transition'), \n",
    "                   ('IDPO:00061', 'transition'), ('IDPO:00054', 'transition'), ('IDPO:00057', 'transition'), \n",
    "                   ('IDPO:00058', 'transition'), ('IDPO:00059', 'transition')]\n",
    "\n",
    "# GO ancestor terms coresponding to CAID2 challenges\n",
    "ancestors = {'GO:0005488': 'binding', 'GO:0003676': 'nucleic acid binding', 'GO:0005515': 'protein binding'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ab573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OBO must have \"ontology: GO\" header (first line)\n",
    "graph = obonet.read_obo(go_obo_file)\n",
    "\n",
    "# Remove all edges which are not \"is_a\"\n",
    "to_remove = []\n",
    "for e in graph.edges:\n",
    "    if e[2] != 'is_a':\n",
    "        to_remove.append((e[0], e[1]))\n",
    "for ele in to_remove:\n",
    "    graph.remove_edge(*ele)\n",
    "    \n",
    "# Create children table\n",
    "data_go = []    \n",
    "for node in graph.nodes(data=True):\n",
    "    challenge = ancestors.get(node[0])\n",
    "    if challenge is not None:\n",
    "        data_go.append([node[0], challenge])\n",
    "        for children in networkx.ancestors(graph, node[0]): \n",
    "            data_go.append([children, challenge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a327bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDPO:00076</td>\n",
       "      <td>disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDPO:00077</td>\n",
       "      <td>disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDPO:00078</td>\n",
       "      <td>disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IDPO:00501</td>\n",
       "      <td>linker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDPO:00502</td>\n",
       "      <td>linker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>GO:0051010</td>\n",
       "      <td>protein binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>GO:0086080</td>\n",
       "      <td>protein binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>GO:0017058</td>\n",
       "      <td>protein binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>GO:0035373</td>\n",
       "      <td>protein binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>GO:0001098</td>\n",
       "      <td>protein binding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3087 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_id        challenge\n",
       "0     IDPO:00076         disorder\n",
       "1     IDPO:00077         disorder\n",
       "2     IDPO:00078         disorder\n",
       "3     IDPO:00501           linker\n",
       "4     IDPO:00502           linker\n",
       "...          ...              ...\n",
       "3082  GO:0051010  protein binding\n",
       "3083  GO:0086080  protein binding\n",
       "3084  GO:0017058  protein binding\n",
       "3085  GO:0035373  protein binding\n",
       "3086  GO:0001098  protein binding\n",
       "\n",
       "[3087 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_challenge = pd.DataFrame(data=data_idpo + data_go, columns=['term_id', 'challenge']).drop_duplicates()\n",
    "df_challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1453d",
   "metadata": {},
   "source": [
    "## Process DisProt annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2227c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DisProt annotations\n",
    "disprot_old = {}\n",
    "with open(disprot_old_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        disprot_old[obj[\"disprot_id\"]] = obj\n",
    "        \n",
    "disprot_new = {}\n",
    "with open(disprot_new_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        disprot_new[obj[\"disprot_id\"]] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfd44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new annotations (delta = new - old)\n",
    "dataset = []\n",
    "for disprot_id in disprot_new:\n",
    "    if disprot_id not in disprot_old and \"obsolete\" not in disprot_new[disprot_id] and \"X\" not in disprot_new[disprot_id][\"sequence\"]:\n",
    "        # Filter out obsolete regions\n",
    "        disprot_new[disprot_id][\"regions\"] = [region for region in disprot_new[disprot_id][\"regions\"] if \"obsolete\" not in region]\n",
    "        if disprot_new[disprot_id][\"regions\"]:\n",
    "            dataset.append(disprot_new[disprot_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1633f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fasta\n",
    "with open(fasta_new_file, \"w\") as fout:\n",
    "    for obj in dataset:\n",
    "        fout.write(\">{}|{}\\n{}\\n\".format(obj['disprot_id'], obj['acc'], obj['sequence']))\n",
    "\n",
    "with open(fasta_old_file, \"w\") as fout:\n",
    "    for disprot_id, obj in disprot_old.items():\n",
    "        if \"obsolete\" not in obj:\n",
    "            fout.write(\">{}|{}\\n{}\\n\".format(obj['disprot_id'], obj['acc'], obj['sequence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_columns = ['disprot_id', 'acc', 'ncbi_taxon_id', 'organism', 'sequence']\n",
    "df = pd.json_normalize(data=dataset, record_path=['regions'], meta=entry_columns, meta_prefix='', record_prefix='')\n",
    "df.to_csv(raw_dataset_file, sep=\"\\t\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_columns = [\"start\", \"end\", \"term_id\"]\n",
    "df = df.loc[:, entry_columns + region_columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the per-protein dataframe into a per-residue dataframe \n",
    "df_regions = df.apply(expand_region, axis=1).loc[:, [\"disprot_id\", \"term_id\", \"reg_position\"]].copy(deep=True)\n",
    "df_regions = pd.merge(left=df_regions, right=df_challenge, how=\"inner\", left_on=\"term_id\", right_on=\"term_id\").drop(columns=[\"term_id\"])\n",
    "df_regions = df_regions.explode(\"reg_position\").drop_duplicates()\n",
    "df_regions['has_region'] = 1\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d041721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pivot table. Transpose challenge values into columns \n",
    "df_regions = pd.pivot_table(\n",
    "    df_regions,\n",
    "    columns=\"challenge\",\n",
    "    index=['disprot_id', 'reg_position'],\n",
    "    values='has_region')\n",
    "df_regions = df_regions.reset_index()\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset sequences (1 residue per row)\n",
    "df_sequence = df.apply(expand_sequence, axis=1).copy(deep=True).drop(columns=[\"ncbi_taxon_id\", \"organism\", \"start\", \"end\", \"sequence\", \"term_id\"])\n",
    "df_sequence = df_sequence.explode(\"seq_aa\")\n",
    "df_sequence[['pos', 'aa']] = pd.DataFrame(df_sequence['seq_aa'].tolist(), index=df_sequence.index)\n",
    "df_sequence = df_sequence.drop(columns='seq_aa').drop_duplicates()\n",
    "df_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sequence positions not mapping to any DisProt region\n",
    "df_regions = pd.merge(left=df_regions, right=df_sequence, how=\"right\", left_on=[\"disprot_id\", \"reg_position\"], right_on=[\"disprot_id\", \"pos\"])\n",
    "df_regions.drop(columns=\"reg_position\", inplace=True)\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19bc31",
   "metadata": {},
   "source": [
    "## Map PDB onbserved positions using SIFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sifts = pd.read_csv(sifts_file, sep=\"\\t\", header=1)\n",
    "# Filter for dataset entries\n",
    "df_sifts = df_sifts.loc[df_sifts['SP_PRIMARY'].isin(df_regions['acc'])]\n",
    "# Explode observed regions \n",
    "df_sifts = df_sifts.apply(expand_region, start_col=\"SP_BEG\", end_col=\"SP_END\", axis=1)\n",
    "df_sifts = df_sifts.explode(\"reg_position\")\n",
    "df_sifts = df_sifts.loc[:, ['SP_PRIMARY', 'reg_position']].drop_duplicates().reset_index(drop=True).rename(columns={\"SP_PRIMARY\": \"acc\"})\n",
    "df_sifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.merge(df_regions, df_sifts, left_on=[\"acc\", \"pos\"], right_on=[\"acc\", \"reg_position\"], how=\"left\")\n",
    "df_regions.rename(columns={\"reg_position\": \"pdb\"}, inplace=True)\n",
    "df_regions.loc[df_regions['pdb'].notnull(), 'pdb'] = 1.0\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22517c48",
   "metadata": {},
   "source": [
    "## Add AlphaFold prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for af_file in os.listdir(alphafold_dir):\n",
    "    df_list.append(pd.read_csv(\"{}/{}\".format(alphafold_dir, af_file), sep='\\t'))\n",
    "df_af = pd.concat(df_list, ignore_index=True)\n",
    "del df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: rename depends on the version (only full lenght predictions should be used)\n",
    "df_af['acc'] = df_af['name'].apply(lambda x: x.replace('AF-','').replace('-F1-model_v3',''))\n",
    "df_af = df_af.rename(columns={\"disorder\": \"af-disorder\", \"disorder-25\": \"af-rsa\", \"binding-25-0.581\": \"af-binding\"})\n",
    "df_af = df_af[[\"acc\", \"pos\", \"aa\", \"af-disorder\", \"af-rsa\", \"af-binding\"]]\n",
    "df_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3285dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.merge(df_regions, df_af, on=[\"acc\", \"pos\", \"aa\"], how=\"left\")\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3db36",
   "metadata": {},
   "source": [
    "## Write files\n",
    "\n",
    "Challenge definitions\n",
    "\n",
    "- The first list are the columns to be considered as positive (any)\n",
    "- The second list (mask) are the columns to be considered as negative (any)\n",
    "- If the second list is not provided all non-positives are considered negatives\n",
    "- In case of conflicts, the positives always overwrite the negatives\n",
    "- If mask is provided proteins without at least one residue that could be masked (even when overwritten by a positive) are excluded (e.g. only proteins with PDB observed residues are considered) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "head_cols = ['disprot_id', 'acc', 'pos', 'aa']\n",
    "disprot_cols = list(df_challenge['challenge'].unique())\n",
    "other_cols = sorted(list((set(df_regions.columns.tolist()) - set(head_cols)) - set(disprot_cols)))\n",
    "cols = head_cols + disprot_cols + other_cols\n",
    "print(cols)\n",
    "\n",
    "df_regions = df_regions[cols]\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe\n",
    "df_regions.to_csv(dataset_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the fastas\n",
    "challenges = [[['linker'], []], \n",
    "              [['disorder'], []], \n",
    "              [['protein binding'], []], \n",
    "              [['nucleic acid binding'], []], \n",
    "              [['binding'], []],\n",
    "              [['disorder'], ['pdb']],\n",
    "             ]\n",
    "\n",
    "for challenge, mask in challenges:\n",
    "    \n",
    "    file_name = \"-\".join([\"_\".join(c.split()) for c in challenge])\n",
    "    if mask:\n",
    "        file_name = file_name + \"@\" + \"-\".join([\"-\".join(m.split()) for m in mask])\n",
    "    \n",
    "    with open(\"{}/{}.fasta\".format(references_dir, file_name), \"w\") as fout:\n",
    "        for disprot_id, df_g in df_regions.groupby('disprot_id'):\n",
    "\n",
    "            if mask:\n",
    "                df_g['output'] = '-'\n",
    "                df_g.loc[df_g[mask].notnull().any(axis='columns'), 'output'] = '0'\n",
    "            else:\n",
    "                df_g['output'] = '0'\n",
    "                \n",
    "            df_g.loc[df_g[challenge].notnull().any(axis='columns'), 'output'] = '1'\n",
    "            \n",
    "            # If mask is provided also check the protein has a at least one residue that could be masked (even when overwritten by a positive) \n",
    "            if df_g[challenge].notnull().any(axis='columns').any() and (not mask or df_g[mask].notnull().any(axis='columns').any()):  \n",
    "                fout.write(\">{}\\n{}\\n{}\\n\".format(disprot_id, \"\".join(df_g['aa']), \"\".join(df_g['output'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

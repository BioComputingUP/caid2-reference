{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce28b11f",
   "metadata": {},
   "source": [
    "# ENVs\n",
    "\n",
    "**Comments**  \n",
    "* Variables for directories always starts with '`dir_`' and ends without '`/`'\n",
    "* Variables for dataframes always starts with '`df_`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pjs            = \"/home/martingb/Projects\"\n",
    "# caid-reference\n",
    "dir_main               = f\"{dir_pjs}/2022/caid2-reference\"\n",
    "dir_data               = f\"{dir_main}/data\"\n",
    "dir_data_sifts         = f\"{dir_data}/sifts\"\n",
    "dir_data_alphafold     = f\"{dir_data}/alphafold\"\n",
    "dir_data_disprot       = f\"{dir_data}/disprot\"\n",
    "dir_src                = f\"{dir_main}/src\"\n",
    "dir_tmp                = f\"{dir_main}/tmp\"\n",
    "dir_results            = f\"{dir_main}/results\"\n",
    "dir_results_tables     = f\"{dir_results}/tables\"\n",
    "dir_results_references = f\"{dir_results}/references\"\n",
    "dir_results_imgs       = f\"{dir_results}/imgs\"\n",
    "dir_src_modules        = f\"{dir_src}/modules\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a43a95-07ef-47a4-9865-2ad11c49ce02",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52187c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903970be",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_region(adf: pd.DataFrame, database: str = 'disprot') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if database == 'disprot':\n",
    "        adf[\"reg_position\"] = list(range(int(adf[\"start\"]), int(adf[\"end\"]) + 1, 1))\n",
    "    elif database == 'sifts':\n",
    "        adf[\"sp_position\"] = list(range(int(adf[\"SP_BEG\"]), int(adf[\"SP_END\"]) + 1, 1))\n",
    "    else:\n",
    "        raise ValueError(f\"'{database}' is not a choise for parameter 'database'\")\n",
    "    return adf\n",
    "\n",
    "def expand_seq(adf: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    adf[\"seq_position_aa\"] = [(i+1, aa) for i, aa in enumerate(adf[\"sequence\"])]\n",
    "    return adf\n",
    "\n",
    "def get_closed_intervals(alist : list, min_elems : int) -> list:\n",
    "    \"\"\"\n",
    "    Describe a list of closed intervals as tuples of two ints for each\n",
    "    region with at least the 'min' number of consecutive elements given.\n",
    "    Example:\n",
    "    alist = [2,3,4,5,6,7,8,9,10,11,15,16,17,18,19,20,21,22,23,24]\n",
    "    min_elems = 10\n",
    "    result: [(2,11)]\n",
    "    \"\"\"\n",
    "    intervals = []\n",
    "    interval = (int(alist[0]), int(alist[0]))\n",
    "    for pos in alist[1:]:\n",
    "        pos = int(pos)\n",
    "        if (interval[1] + 1) == pos:\n",
    "            interval = (interval[0], pos)\n",
    "            continue\n",
    "        else:\n",
    "            if (interval[1] - interval[0]) >= min_elems - 1:\n",
    "                intervals.append(interval)\n",
    "            interval = (pos, pos)\n",
    "            continue\n",
    "    if (interval[1]) == alist[-1] and \\\n",
    "       (interval[1] - interval[0]) >= min_elems:\n",
    "        intervals.append((interval[0], alist[-1]))\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac506b",
   "metadata": {},
   "source": [
    "# CAID2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a6179",
   "metadata": {},
   "source": [
    "## Private DisProt json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f\"{dir_data_disprot}/entries_private_caid2.json\")\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    with open(f\"{dir_data_disprot}/entries_private_caid2.json\", \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "        json_private = json_data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b84fbd",
   "metadata": {},
   "source": [
    "## Dataframe for private DisProt entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e84dc",
   "metadata": {},
   "source": [
    "### Columns to take in account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_columns = [ 'disprot_id'\n",
    "               , 'acc'\n",
    "               , 'name'\n",
    "               , 'ncbi_taxon_id'           # int\n",
    "               , 'organism'\n",
    "               , 'sequence'\n",
    "               , 'taxonomy' ]              # list of str (organisms)\n",
    "\n",
    "region_columns = [ \"disprot_namespace\"  # str\n",
    "                 , \"region_id\"          # str\n",
    "                 , \"date\"               # str\n",
    "                 , \"start\"              # int\n",
    "                 , \"end\"                # int\n",
    "                 , \"term_id\"            # str (GO and IDPO terms)\n",
    "                 , \"term_name\"          # str (GO and IDPO description)\n",
    "                 , \"term_namespace\"     # str (GO and IDPO namespace)\n",
    "                 , \"term_ontology\" ]    # str (type of ontology, e.i.: GO, IDPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15375fe0",
   "metadata": {},
   "source": [
    "#### New columns to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_stats_columns = [ \"curator_name\"       # str (Full name)\n",
    "                       , \"curator_orcid\" ]    # str (ORCID ID of curator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disprot_private = pd.json_normalize( data          = json_private\n",
    "                                      , record_path   = ['regions']\n",
    "                                      , meta          = main_columns\n",
    "                                      , meta_prefix   = ''\n",
    "                                      , record_prefix = '' )\n",
    "df_disprot_private = df_disprot_private.loc[:, main_columns + region_columns + region_stats_columns]\n",
    "df_disprot_private"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee87d0",
   "metadata": {},
   "source": [
    "## Load dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ae32c",
   "metadata": {},
   "source": [
    "### Dataframe for ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_ontologies_for_caid2.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_challenges = pd.read_csv(f'{dir_results_tables}/disprot_ontologies_for_caid2.csv', header=0)\n",
    "df_challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee87d0",
   "metadata": {},
   "source": [
    "### Dataframe for private DisProt entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_private.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_disprot_private = pd.read_csv(f'{dir_results_tables}/disprot_private.csv', header=0)\n",
    "df_disprot_private"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e3042",
   "metadata": {},
   "source": [
    "### Dataframe for sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_private_sequences.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_sequence = pd.read_csv(f'{dir_results_tables}/disprot_private_sequences.csv', header=0)\n",
    "df_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67451f0b",
   "metadata": {},
   "source": [
    "### Dataframe for regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_private_regions.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_regions = pd.read_csv(f'{dir_results_tables}/disprot_private_regions.csv', header=0)\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d430a",
   "metadata": {},
   "source": [
    "### Dataframe DisProt sequences with wwPDB (SIFTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_private_sifts.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_sequence_sifts = pd.read_csv(f'{dir_results_tables}/disprot_private_sifts.csv', header=0)\n",
    "df_sequence_sifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb117b",
   "metadata": {},
   "source": [
    "### Dataframe DisProt sequences with Alphafold score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.exists(f'{dir_results_tables}/disprot_private_alphafold.csv')\n",
    "except FileNotFoundError as e:\n",
    "    raise e\n",
    "else:\n",
    "    df_sequence_af = pd.read_csv(f'{dir_results_tables}/disprot_private_alphafold.csv', header=0)\n",
    "df_sequence_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae964236",
   "metadata": {},
   "source": [
    "## Overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93faaf9",
   "metadata": {},
   "source": [
    "### Alphafold-DisProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlaps_merge = pd.DataFrame(columns=['disprot_id'])\n",
    "for challenge in ['disorder', 'transition', 'binding']:\n",
    "    df_disprot_ids_with_af_overlaps = pd.DataFrame(columns=['disprot_id'])\n",
    "    # Challenge + Alphafold\n",
    "    df_sequence_af_challenge = pd.merge( left     = df_sequence_af\n",
    "                                       , right    = df_regions.loc[df_regions['challenge'] == challenge]\n",
    "                                       , left_on  = [\"disprot_id\", 'acc', 'seq_position']\n",
    "                                       , right_on = [\"disprot_id\", 'acc', 'reg_position']\n",
    "                                       , how      = 'left' )\n",
    "    df_sequence_af_challenge['result'] = '-'\n",
    "    df_sequence_af_challenge.loc[df_sequence_af_challenge['lddt'] > 0.7, 'result'] = '0'  # Assigment: 0 for AF order\n",
    "    df_sequence_af_challenge.loc[df_sequence_af_challenge['challenge'].notnull(), 'result'] = '1' # Assigment: 1 for challenge\n",
    "    #df_sequence_af_challenge = df_sequence_af_challenge[(df_sequence_af_challenge['lddt'] > 0.7) & (df_sequence_af_challenge['result'] == '1')]\n",
    "    #\n",
    "    df_sequence_af_challenge = df_sequence_af_challenge.query('lddt > 0.7 & result == \"1\"')\n",
    "    for disprot_id, df_overlaps in df_sequence_af_challenge.groupby(by=['disprot_id']):\n",
    "        list_overlaps = get_closed_intervals(alist = df_overlaps.reg_position.tolist(), min_elems = 10)\n",
    "        # if disprot_id == 'DP02342':\n",
    "        #     print(f\"{challenge}:\\t{list_overlaps}\")\n",
    "        if len(list_overlaps) > 0:\n",
    "            df_disprot_ids_with_af_overlaps = pd.concat( [ df_disprot_ids_with_af_overlaps\n",
    "                                                         , pd.DataFrame({'disprot_id': disprot_id\n",
    "                                                                       , challenge: [list_overlaps]}, columns=['disprot_id', challenge])]\n",
    "                                                       , ignore_index=True)\n",
    "    if not df_overlaps_merge.empty:\n",
    "        df_overlaps_merge = pd.merge( left=df_overlaps_merge\n",
    "                                    , right=df_disprot_ids_with_af_overlaps\n",
    "                                    , left_on='disprot_id'\n",
    "                                    , right_on='disprot_id'\n",
    "                                    , how='outer')\n",
    "    else:\n",
    "        df_overlaps_merge = df_disprot_ids_with_af_overlaps.copy(deep=True)\n",
    "\n",
    "df_overlaps_merge.to_csv(f'{dir_results_tables}/overlaps_disprot_private_af.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93faaf9",
   "metadata": {},
   "source": [
    "### wwPDB-DisProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlaps_merge = pd.DataFrame(columns=['disprot_id'])\n",
    "for challenge in ['disorder', 'transition', 'binding']:\n",
    "    list_disprot_ids = []\n",
    "    df_disprot_ids_with_pdb_overlaps = pd.DataFrame(columns=['disprot_id'])\n",
    "    # Challenge + Alphafold\n",
    "    df_sequence_sifts_challenge = pd.merge( left     = df_sequence_sifts\n",
    "                                          , right    = df_regions.loc[df_regions['challenge'] == challenge]\n",
    "                                          , left_on  = [\"disprot_id\", 'acc', 'seq_position']\n",
    "                                          , right_on = [\"disprot_id\", 'acc', 'reg_position']\n",
    "                                          , how      = 'left' )\n",
    "    # df_sequence_sifts_challenge.loc[(df_sequence_sifts_challenge['sp_position']) == (df_sequence_sifts_challenge['reg_position'])]\n",
    "    df_sequence_sifts_challenge = df_sequence_sifts_challenge.query('sp_position == reg_position')\n",
    "    for disprot_id, df_overlaps in df_sequence_sifts_challenge.groupby(by=['disprot_id']):\n",
    "        list_overlaps = get_closed_intervals(alist = df_overlaps.reg_position.tolist(), min_elems = 10)\n",
    "        # if disprot_id == 'DP02342':\n",
    "        #     print(f\"{challenge}:\\t{list_overlaps}\")\n",
    "        if len(list_overlaps) > 0:\n",
    "            df_disprot_ids_with_pdb_overlaps = pd.concat( [ df_disprot_ids_with_pdb_overlaps\n",
    "                                                         , pd.DataFrame({'disprot_id': disprot_id\n",
    "                                                                       , challenge: [list_overlaps]}, columns=['disprot_id', challenge])]\n",
    "                                                       , ignore_index=True)\n",
    "    if not df_overlaps_merge.empty:\n",
    "        df_overlaps_merge = pd.merge( left=df_overlaps_merge\n",
    "                                    , right=df_disprot_ids_with_pdb_overlaps\n",
    "                                    , left_on='disprot_id'\n",
    "                                    , right_on='disprot_id'\n",
    "                                    , how='outer')\n",
    "    else:\n",
    "        df_overlaps_merge = df_disprot_ids_with_pdb_overlaps.copy(deep=True)\n",
    "\n",
    "df_overlaps_merge.to_csv(f'{dir_results_tables}/overlaps_disprot_private_pdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad5962",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669481f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder destination for plots\n",
    "os.makedirs(f\"{dir_results_imgs}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee44a3d",
   "metadata": {},
   "source": [
    "### Load Dataframe of DisProt entries and tag challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment: some regions with are not matched with IDPO and GO terms because were not considerer to be part of CAID2 challenge.\n",
    "# Example:\n",
    "#    IDPO:00024 (molecular recognition display site ) and its children\n",
    "#    IDPO:00505 (self-regulatory activity) and its children\n",
    "#    GO terms that are not child of challenge ancestors\n",
    "df_disprot_private_challenges = pd.merge( left  = df_disprot_private\n",
    "                                        , right = df_challenges\n",
    "                                        , how   = \"left\"\n",
    "                                        , on    = \"term_id\" )\n",
    "df_disprot_private_challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7885c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disprot_private_challenges_core = df_disprot_private_challenges.query('challenge.notnull()').copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b26bc8",
   "metadata": {},
   "source": [
    "### Curators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc829b",
   "metadata": {},
   "source": [
    "#### Who curated the DisProt entries for the CAID2 dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce382dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disprot_private_challenges_core.query('challenge.notnull()')['curator_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_curators = df_disprot_private_challenges_core.groupby('curator_name')['challenge'].apply(lambda x: x.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db89b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig = s_curators.unstack().plot( kind='barh'\n",
    "                         , stacked=True\n",
    "                         , figsize=(10,15)\n",
    "                         , sort_columns=True).set(ylabel=\"\")[0].get_figure()\n",
    "fig.savefig(f\"{dir_results_imgs}/barh_curators.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490db3d",
   "metadata": {},
   "source": [
    "### Lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc8039",
   "metadata": {},
   "source": [
    "### Lenght with `negative` and `positive` residues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff50a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.caid2_reference3102': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2991660129badcba6c5c5e1ee996d0a60c2dfaf302bb501f5ec3e2a8e54caa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
